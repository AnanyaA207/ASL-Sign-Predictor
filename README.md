# ğŸ¤Ÿ ASL Sign Predictor (MediaPipe + Machine Learning)

Real-time American Sign Language (ASL) letter recognition game using your webcam, powered by MediaPipe hand tracking and a machine learning model. Learn and practice ASL one sign at a time with visual references!

---

## ğŸ“¸ Demo



---

## ğŸ§  How It Works

This project uses **MediaPipe** to detect 3D hand landmarks and a **RandomForestClassifier** (trained on ASL alphabet gestures) to predict the signed letter.

- ğŸ‘‹ Detects hand via webcam
- ğŸ“ Extracts 21 hand landmarks (x, y, z)
- ğŸ§  Classifies your sign using a trained `.pkl` model
- ğŸ“· Shows a reference image for each letter so you can copy the pose

---

## ğŸ—ï¸ Model Info

Model type: RandomForestClassifier (via scikit-learn)
Features: 21 3D hand landmarks â†’ 63 values total (x, y, z for each point)
Training data: Preprocessed images from the [ASL Alphabet Dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)
Training method: MediaPipe's landmark extraction â†’ fed into classical ML model

### ğŸ”§ Requirements

Make sure you have these installed:

```bash
pip install opencv-python mediapipe scikit-learn numpy joblib
